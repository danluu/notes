* questions
  Think about self-triggering always block section
  What's a pulse stretcher?
  Remember what a schmidtt trigger is?
  What's the deal with clock domains on CN? I don't recall ever having to deal with sync issues

* Synthesis gotchas
** sensitivity list / latching
   always blocks without posedge or negedge turn into latches, regardless of sensitivity list
   i.e., having an incomplete sensitivity list will cause incorrect pre-synthesis simulation
** ordering inside block
   using a temporary variable before it's assigned will not synthesize correctly

   always @ (a or b or c or d) begin
     o = a & b | temp;
     temp = c & d;
   end

   will synthesize to the same thing, even if we swap the two lines
   i.e., we'll get an and-or gate post-synthesis either way
** functions
   functions always produce combinational logic.
   Creating latching behavior will cause a problem
** case statements
   A case statement is normally equivalent to a series of "if else" statements

   (synopsis)
   //synopsis full_case

   This says that case statement is fully defined; unused cases should be don't cares.
   In addition to the obvious effect,
   this can cause logic to get optimized away in synthesis
   
   Note that we can make a statement full, in simulation, by adding a default
   Could have the default go to X

   Otherwise, we'll latch the last input if we fall into an empty case

   //synopsis parallel_case
   
   This causes all cases to be tested in parallel, even if we have overlapping cases,
   where you'd normally get a priority encoder

   But, if we want that, we can also do it 'manually'
   Say we have a case statement with the following:

   1??
   ?1?
   ??1

   Instead of using parallel_case, which will cause a simulation mismatch, we can do this:
  
   1??
   01?
   001

** casex vs. casez
   casex matches Xs as don't cares (in both the case expression and the item)
   Post-sythesis, the x will propogate and cause the gate level model to X out

** translate_on / translate_off
   Bad idea, most of the time, except for debug logic

   Interesting exception is a D-flip flop
   If we code it in the obvious style (negedge resetb, negedge setb), asserting both and then removing one fails to simulate correctly even though synthesis works
** #delays
   Won't synthesize, obv.

   We may need these when doing mixed verilog / gate level simulations, due to hold time issues
* blocking vs. non-blocking assignments
  General guideline is non-blocking for sequential and blocking for combinational. But why?
  Note that if we have combinational and sequential logic in the same block, we should use non-blocking assignments
  Should never mix blocking and non-blocking in the same block

  Note that seperate blocks can be scheduled in any order
** blocking assignments
   Can think of it as a one step process
   evaluate RHS, update LHS. Blocks other assignments *in the same block* until it's finished
   Can have race conditions if used in multiple blocks (say we have two different posedge clk blocks, like we would for two chunks of sequential logic)
** non-blocking assignments
   Can think of it as a two step process
   1. Evaluate RHS of all non-blocking statements
   2. Update LHS of all non-blocking statements

   Note: if we re-assign a variable multiple times within an always block, the last one wins
   If we assign from seperate blocks, that's a race condition
** verilog "stratified event queue"
*** Active events
    Blocking assignments, non-blocking RHS, continuous assigments, $display, primitives
*** Inactive events
    #0 blocking assignments. Don't use this!
*** NBA
    Update non-blocking things. This can re-trigger more active events
*** Postponed (monitor events queue)
    $monitor, $strobe
** self-triggering always blocks
   Can't be done with blocking assignments. We could try to use a #delay, but, say we do this:
   always @(clk) #10 clk = ~clk;
   
   Blocking assignment must complete before edge-trigger event can be scheduled.
   When trigger event is scheduled, assignment has completed,
   so we don't have a trigger from within the block to trigger transition
* resets
  General guideline: every FF should have a reset, except perhaps follower FFs in high speed logic (shift register)
  Cummings prefer asyc resets
** synchronus resets
   Pros: don't have to worry about spurious reset from glitches. Also, more noise tolerant
   Smaller logic, better compatability with some cycle based simulators
   Cons: If reset tree has high fanout, and reset is late arriving, have to schedule time for reset
   May need to use a pulse stretcher to get a wide enough reset pulse
   Synchronus reset may put logic on the datapath (timing issue)

   May be annoying with some design styles. Reset doesn't happen until we have a clock edge, but, if we have, e.g., an internal tri-state bus,
   we want to reset on power up to avoid contention
** asynchronus resets
   Must handle reset removal correctly! If we release reset near a clock edge, we may get metastability
   This means we need a reset synchronizer.

   Design is simple. If we have two DFFs in a row, with our external reset going to those resets, that will synchronize the reset.
   First DFF gets reset as normal. Second is to remove any metastability

   If we have multiple clock domains, we need a synchronizer for each clock domain
   Depending on the design, we may need a certain sequence of reset removal

   We can do this by having the output of one synchronier (reset) be the input of another synchornizer (normally, the external reset)

   To avoid reset glitches, we may want a schmidtt trigger on the reset input.
   Also, to filter glitches, we can use a delay line and an or gate

   TODO: go back and read section on precise multi-ASIC resets
* FIFOs (for clock domain crossing)
** Simple synchronus implementation:
   Use a counter that increments on a read and decrements on a write
   Full at counter = CONSTANT, empty at counter = 0

   Doesn't work for an async counter, because the counter would have to support two clock domains

** Async design: read/write pointers
   Write pointer points to next word to be written. 
   Read pointer points to next word to be read.
   
   At reset, both pointers point to 0.
   After the first write, write pointer advances and empty flag is cleared
   We also immediately drive the data at 0 onto the read port
   
   FIFO empty when pointers ==, also full when pointers ==
   How to determine which?
   We can add one extra bit. If that bit is the same, empty. If different, full
** counter
   How do we sync a count between two clock domains?
   Every bit of an n-bit counter can change during an increment

   One way to handle this is to hold values in a holding register and pass a ready signal.
   When the other domain sees the ready signal it sends an ack
   
   Another approach is to use a gray code counter

   But, note that if we want to do the thing above with the MSB, we can't use a true gray code
   If we use a standard reflected gray code, we can flip MSB-1 in the bottom half to make
   the bottom half match the top half instead of mirror it. But, this causes two 2-bit changes.

   full an empty are implementation dependent
   One obvious choice is to put empty in the read domain and full in the write domain, so that 
   the external inputs see them immediately

   // TODO: read FIFO paper #2
* synchronization techniques (clock domain crossing / async signals)
  Just go through 2 flip flops. Maybe 3 for high speed designs. Note that MTBF ~ 1 / (freq * switching_freq)

  We should register signals before sending them out. This removes glitches, which increase the probability of metastability
** fast to slow
   Might change twice before it can be sampled, or be too close to the sampling edges of the slower domain

   Note that slow to fast isn't generally a problem, as long as the fast domain is 1.5X or more (why not 2x, ala nyquist?)
   So, maybe we can just use a 2 flip flop synchronizer
   
   "three edge" rule
   CDC signal must be 1.5x the cycle width of the recieving domain clock period, hence, three clock edges

   Why? So, it's obviously bad if the CDC is less than the cycle width.
   What if it's just slightly greater?
   The rising edge could catch t_su of the first edge, and the falling edge could catch t_h of the second edge
*** Open loop solution
    Make sure the pulse is stretched to obey the 3 edge rule
*** Closed loop solution
    Require ack signal from recieving domain before allowing sending domain to change control signals
    This can be much slower than the open loop solution
** multi-bit CDC
   Using synchronizers on each individual bit isn't sufficient.
   Any skew between the two signals can cause them to get synced differently

   Strategies
*** consolidate into single bit
    Not always possible, obv.
*** use synchronized load signal
**** multi-cycle path (MCP) formulation
     Send both data and en at the same time. en is synced and sends an ack back
     Once sending side gets the ack it can change the data

     Pros: Sending domain doesn't need to figure out correct pulse width
     Sending domain just needs to switch enable. Doesn't need to switch back

     How does the enable pulse work? It's typical to use a synchronized enable pulse
     We can use two FFs to get rid of metastability and sync the signal
     Then one output goes directly into an xor, and the other goes through another DFF before going to an XOR, which will create a pulse

     We also produce a 'q' (non pulsed) output directly from the 3rd DFF. This can be used to generate the ack signal, which goes
     into an identical pulse generator on the recieving side
*** gray codes
    Sometimes don't need to sample every bit
*** async FIFO
    See notes above on FIFO, and fifo.v
*** 1-deep / 2-register FIFO
    TODO: go back and read this section
    
  
